{"cells":[{"cell_type":"markdown","id":"d3ec6217-3568-4698-a95a-52b8ad2f3399","metadata":{"id":"d3ec6217-3568-4698-a95a-52b8ad2f3399"},"source":["# **Assignment: Advanced Text Preprocessing**\n","\n","In this assignment, you will explore more libraries and techniques for text preprocessing . Follow the steps below and implement your solutions in Python.\n","\n","---\n","\n","## **Part 1: Text Preprocessing**\n","Expand the preprocessing steps beyond NLTK. Perform the following tasks:\n","\n","### **1. Tokenization**\n","Use **spaCy** and **TextBlob** libraries for tokenization.\n","\n","- Compare tokenization using **spaCy** and **TextBlob**.\n","- Explain any differences in the output.\n","\n","### **2. Lemmatization**\n","Use **spaCy** and **TextBlob** lemmatizers.\n","\n","- Perform lemmatization on a given sample dataset.\n","- Compare results with **WordNetLemmatizer** from NLTK.\n","\n","### **3. Stemming**\n","Use additional stemmers, such as:\n","\n","- **Snowball Stemmer** from NLTK\n","- **Lancaster Stemmer**\n","\n","Compare their outputs with **PorterStemmer** from NLTK.\n","\n","### **4. Stopwords Removal**\n","Use stopword lists from **Gensim** and **spaCy**, and compare them with the NLTK stopword list.\n","\n","- Note any additional or missing stopwords between libraries.\n","\n","### **5. Other Text Cleaning Techniques**\n","Explore the following additional cleaning techniques:\n","\n","- **Lowercasing**\n","- **Removing special characters**\n","- **Removing numbers**\n","- **Handling contractions using the `contractions` library**.\n","\n","---\n","\n","\n","## **Bonus (Optional)**\n","- Implement **Lemmatization** and **Stemming** in the feature extraction step to observe their impact on the resulting n-grams.\n","- Explore **preprocessing pipelines** combining multiple steps (e.g., using **spaCy pipelines** or **scikit-learn Pipelines**).\n","\n","---\n","\n","## **Submission Requirements**\n","- Code implementation for each step.\n","- Written explanation comparing different approaches and libraries.\n"]},{"cell_type":"markdown","id":"54f8020d-cf4d-40f7-b65e-658d67535916","metadata":{"id":"54f8020d-cf4d-40f7-b65e-658d67535916"},"source":["# Install the Required Libraries"]},{"cell_type":"code","execution_count":null,"id":"d80746c8-25db-472e-8a6c-6060dad65313","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d80746c8-25db-472e-8a6c-6060dad65313","executionInfo":{"status":"ok","timestamp":1746953345801,"user_tz":-300,"elapsed":2736,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"1e509bde-6de3-48b6-bb65-cafd8f31f638"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]}],"source":["!pip install nltk"]},{"cell_type":"code","source":["!pip install contractions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNJJV18LiO6U","executionInfo":{"status":"ok","timestamp":1746953383984,"user_tz":-300,"elapsed":3847,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"eea3d0b1-0276-4028-ca46-cb12935f7c39"},"id":"sNJJV18LiO6U","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting textsearch>=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n","Collecting anyascii (from textsearch>=0.0.21->contractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n","Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n","  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"]}]},{"cell_type":"markdown","id":"37325bbb-1be2-4f27-8c8f-b849ca1e4a70","metadata":{"id":"37325bbb-1be2-4f27-8c8f-b849ca1e4a70"},"source":["# Import the Required Libraries"]},{"cell_type":"code","execution_count":null,"id":"9ddaa1e7-2f62-4376-af13-fa22ba645a9c","metadata":{"id":"9ddaa1e7-2f62-4376-af13-fa22ba645a9c"},"outputs":[],"source":["import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer, PorterStemmer\n","import string\n","import re\n","import contractions"]},{"cell_type":"markdown","id":"99c09e79-28ec-4a0d-90e5-cfba91c2ab25","metadata":{"id":"99c09e79-28ec-4a0d-90e5-cfba91c2ab25"},"source":["# Download necessary NLTK data if not already available"]},{"cell_type":"code","execution_count":null,"id":"8ce1111b-392f-4864-ac2c-b5d565bcf896","metadata":{"id":"8ce1111b-392f-4864-ac2c-b5d565bcf896","outputId":"6e039be3-775a-4456-c2e8-e419fc240124"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\waqar\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping corpora\\stopwords.zip.\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\waqar\\AppData\\Roaming\\nltk_data...\n"]},{"name":"stdout","output_type":"stream","text":["Stop words: {'down', 'our', 'who', 'because', 'had', 'they', \"we're\", 'same', \"you'd\", 'has', \"shan't\", 'should', \"haven't\", 'd', \"he'd\", 'too', \"shouldn't\", 'where', 'above', \"hadn't\", 'during', 'under', 'in', 'have', 'you', 'needn', 'herself', 'out', 'which', 'how', 'until', \"isn't\", 'whom', 'for', \"it'd\", 'the', 'between', 'doing', 'with', 'hers', 'so', 'it', 'them', 'there', 'itself', 'weren', 'only', 'through', 'having', 'what', 'ain', 'myself', 'then', \"should've\", 'again', 'me', 'mustn', 'but', \"mustn't\", 'him', 'those', 'into', 'a', \"we'll\", \"we've\", 'other', 'just', 'their', 're', 'few', 'didn', 'not', \"needn't\", \"they'll\", 'further', 'theirs', \"you're\", 'before', 'if', 'shan', 'any', 'being', \"wouldn't\", \"don't\", \"that'll\", \"didn't\", 'while', 'this', 'its', \"aren't\", 'wasn', \"weren't\", 'will', 'when', 'some', \"mightn't\", \"she's\", 'her', 'of', \"he's\", 'nor', 'your', 'haven', 'off', 'she', 'such', 'more', 'than', 's', 'ours', 'y', 'to', 'all', 'or', 'hasn', 'shouldn', \"it'll\", 'why', \"you've\", 'do', \"i've\", 'was', 'an', 'yours', \"it's\", 'hadn', \"couldn't\", \"hasn't\", 'mightn', 'aren', 'i', \"doesn't\", 'm', 'o', 'does', \"we'd\", 'won', 'ourselves', 'his', 'did', 'no', 'after', 'about', \"i'd\", 'from', 'that', 'ma', \"wasn't\", 'against', 'can', 'wouldn', 'he', \"they're\", 'once', \"they'd\", 've', \"won't\", 'be', 'both', 'am', 't', \"he'll\", 'below', 'by', \"she'd\", 'isn', 'doesn', 'as', \"she'll\", 'on', 'these', 'been', 'at', 'are', 'over', 'up', \"i'm\", 'each', \"i'll\", 'now', 'yourself', 'here', 'themselves', 'couldn', \"they've\", 'll', 'very', 'and', 'own', 'don', 'yourselves', 'is', 'we', \"you'll\", 'himself', 'most', 'were', 'my'}\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\waqar\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","# Printing the stopwords in English\n","stop_words = set(stopwords.words('english'))\n","print(\"Stop words:\", stop_words)\n"]},{"cell_type":"markdown","id":"4c6333bf-9cf2-470a-871e-eeb50fc308de","metadata":{"id":"4c6333bf-9cf2-470a-871e-eeb50fc308de"},"source":["# Create a Dummy Dataset"]},{"cell_type":"code","execution_count":null,"id":"b3f0c263-e6f3-47e1-b1a3-ad96858894bf","metadata":{"id":"b3f0c263-e6f3-47e1-b1a3-ad96858894bf","outputId":"ca6b74d8-dde0-4227-d48d-ee3d5de7dbf4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Muslims fast during the month of Ramadan to cleanse their body and soul.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>The better player played well and he is a runner</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID  \\\n","0   1   \n","1   2   \n","2   3   \n","3   4   \n","4   5   \n","5   6   \n","\n","                                                                                         Text  \n","0  The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.  \n","1     Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.  \n","2          Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.  \n","3                    Muslims fast during the month of Ramadan to cleanse their body and soul.  \n","4    Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.  \n","5                                            The better player played well and he is a runner  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# Create the DataFrame\n","data = {\n","    'ID': [1, 2, 3, 4, 5,6],\n","    'Text': [\n","        \"The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.\",\n","        \"Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\",\n","        \"Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\",\n","        \"Muslims fast during the month of Ramadan to cleanse their body and soul.\",\n","        \"Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\",\n","        \"The better player played well and he is a runner\"\n","    ]\n","}\n","\n","# Adjusting pandas options to display full content in the dataframe\n","pd.set_option('display.max_colwidth', None)\n","\n","df = pd.DataFrame(data)\n","df"]},{"cell_type":"markdown","id":"d724bd54-52c5-4ea8-a6db-3b761f9ac46c","metadata":{"id":"d724bd54-52c5-4ea8-a6db-3b761f9ac46c"},"source":["## Understanding of Regular Expressions (RE)"]},{"cell_type":"code","execution_count":null,"id":"9285dd41-feda-423d-83f2-85857515c5af","metadata":{"id":"9285dd41-feda-423d-83f2-85857515c5af","outputId":"f0bf3826-08fc-4cdc-f88d-4ec5fb7c77da"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Text</th>\n","      <th>Words_Starting_With_A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.</td>\n","      <td>[an, Arabic, and]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.</td>\n","      <td>[as]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.</td>\n","      <td>[a, act, aimed, at]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Muslims fast during the month of Ramadan to cleanse their body and soul.</td>\n","      <td>[and]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.</td>\n","      <td>[an, annual]</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>The better player played well and he is a runner</td>\n","      <td>[and, a]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID  \\\n","0   1   \n","1   2   \n","2   3   \n","3   4   \n","4   5   \n","5   6   \n","\n","                                                                                         Text  \\\n","0  The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.   \n","1     Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.   \n","2          Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.   \n","3                    Muslims fast during the month of Ramadan to cleanse their body and soul.   \n","4    Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.   \n","5                                            The better player played well and he is a runner   \n","\n","  Words_Starting_With_A  \n","0     [an, Arabic, and]  \n","1                  [as]  \n","2   [a, act, aimed, at]  \n","3                 [and]  \n","4          [an, annual]  \n","5              [and, a]  "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# Function to find all words starting with 'a'\n","# \\b: This is the word boundary metacharacter.\n","# \\w: This metacharacter stands for \"word character\".\n","def find_words_starting_with_a(text):\n","    pattern = r'\\ba\\w*'\n","    return re.findall(pattern, text, re.IGNORECASE)\n","\n","# Apply the function to the DataFrame\n","df['Words_Starting_With_A'] = df['Text'].apply(find_words_starting_with_a)\n","\n","df"]},{"cell_type":"code","execution_count":null,"id":"06ae4af8-7f43-4a09-9b97-6ce6f2d4a769","metadata":{"id":"06ae4af8-7f43-4a09-9b97-6ce6f2d4a769","outputId":"ce4ff9e1-e233-42c4-fce8-a2f0ced6edc8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Muslims fast during the month of Ramadan to cleanse their body and soul.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>The better player played well and he is a runner</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID  \\\n","0   1   \n","1   2   \n","2   3   \n","3   4   \n","4   5   \n","5   6   \n","\n","                                                                                         Text  \n","0  The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.  \n","1     Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.  \n","2          Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.  \n","3                    Muslims fast during the month of Ramadan to cleanse their body and soul.  \n","4    Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.  \n","5                                            The better player played well and he is a runner  "]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["df.drop(df.columns[-1], axis=1, inplace=True)\n","df"]},{"cell_type":"markdown","id":"b2f1bd70-1f44-41b6-b67f-dcdb9a20d4a4","metadata":{"id":"b2f1bd70-1f44-41b6-b67f-dcdb9a20d4a4"},"source":["# Create the Functions of Data Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"79983545-3134-4f5c-9f49-49f54d5df138","metadata":{"id":"79983545-3134-4f5c-9f49-49f54d5df138"},"outputs":[],"source":["# Initialize Lemmatizer and Stemmer\n","lemmatizer = WordNetLemmatizer()\n","stemmer = PorterStemmer()\n","\n","# Function 1: Expanding contractions\n","def expand_contractions(text):\n","    return contractions.fix(text)\n","\n","# Function 2: Lowercasing text\n","def lowercase_text(text):\n","    return text.lower()\n","\n","# Function 3: Tokenization\n","def tokenize_text(text):\n","    return word_tokenize(text)\n","\n","# Function 4: Removing punctuation\n","def remove_punctuation(tokens):\n","    return [word for word in tokens if word not in string.punctuation]\n","\n","# Function 5: Removing numbers\n","def remove_numbers(tokens):\n","    return [word for word in tokens if not word.isdigit()]\n","\n","# Function 6: Removing special characters\n","def remove_special_characters(tokens):\n","    return [re.sub(r'[^A-Za-z0-9]+', '', word) for word in tokens if word]\n","\n","# Function 7: Removing stopwords\n","def remove_stopwords(tokens):\n","    stop_words = set(stopwords.words('english'))\n","    return [word for word in tokens if word not in stop_words]\n","\n","# Function 8: Lemmatization\n","def lemmatize_text(tokens):\n","    return [lemmatizer.lemmatize(word) for word in tokens]\n","\n","# Function 9: Stemming\n","def stem_text(tokens):\n","    return [stemmer.stem(word) for word in tokens]\n","\n","# Function 10: Normalization (e.g., converting currency symbols to words)\n","def normalize_text(tokens):\n","    return [re.sub(r'\\$', 'dollar', word) for word in tokens]\n","\n","# Function 11: Text standardization (e.g., standardizing variations of \"U.S.A.\" to \"USA\")\n","def standardize_text(tokens):\n","    return [re.sub(r'u\\.s\\.a\\.', 'USA', word) for word in tokens]\n","\n"]},{"cell_type":"markdown","id":"1f134dcc-b39d-42e3-9408-8cb2dc3cb697","metadata":{"id":"1f134dcc-b39d-42e3-9408-8cb2dc3cb697"},"source":["# Main function to call all preprocessing steps"]},{"cell_type":"code","execution_count":null,"id":"b0ad89c5-d30f-4f70-9109-e221e833e83e","metadata":{"id":"b0ad89c5-d30f-4f70-9109-e221e833e83e","outputId":"f94f35a5-5745-4195-e058-78e5e7c6ff8a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Text</th>\n","      <th>Processed_Text_Lemmatization</th>\n","      <th>Processed_Text_Stemming</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.</td>\n","      <td>quran holy book islam written arabic muslim recite daily</td>\n","      <td>quran holi book islam written arab muslim recit daili</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.</td>\n","      <td>prophet muhammad pbuh born mecca regarded last prophet islam</td>\n","      <td>prophet muhammad pbuh born mecca regard last prophet islam</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.</td>\n","      <td>zakat mandatory act charity islam aimed helping le fortunate</td>\n","      <td>zakat mandatori act chariti islam aim help le fortun</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Muslims fast during the month of Ramadan to cleanse their body and soul.</td>\n","      <td>muslim fast month ramadan cleanse body soul</td>\n","      <td>muslim fast month ramadan cleans bodi soul</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.</td>\n","      <td>hajj annual pilgrimage mecca every muslim must perform life</td>\n","      <td>hajj annual pilgrimag mecca everi muslim must perform life</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>The better player played well and he is a runner</td>\n","      <td>better player played well runner</td>\n","      <td>better player play well runner</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID  \\\n","0   1   \n","1   2   \n","2   3   \n","3   4   \n","4   5   \n","5   6   \n","\n","                                                                                         Text  \\\n","0  The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.   \n","1     Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.   \n","2          Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.   \n","3                    Muslims fast during the month of Ramadan to cleanse their body and soul.   \n","4    Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.   \n","5                                            The better player played well and he is a runner   \n","\n","                                   Processed_Text_Lemmatization  \\\n","0      quran holy book islam written arabic muslim recite daily   \n","1  prophet muhammad pbuh born mecca regarded last prophet islam   \n","2  zakat mandatory act charity islam aimed helping le fortunate   \n","3                   muslim fast month ramadan cleanse body soul   \n","4   hajj annual pilgrimage mecca every muslim must perform life   \n","5                              better player played well runner   \n","\n","                                      Processed_Text_Stemming  \n","0       quran holi book islam written arab muslim recit daili  \n","1  prophet muhammad pbuh born mecca regard last prophet islam  \n","2        zakat mandatori act chariti islam aim help le fortun  \n","3                  muslim fast month ramadan cleans bodi soul  \n","4  hajj annual pilgrimag mecca everi muslim must perform life  \n","5                              better player play well runner  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Main function to call preprocessing step-by-step\n","def preprocess_text(text, use_stemming=False):\n","    # Step 1: Expand contractions\n","    text = expand_contractions(text)\n","\n","    # Step 2: Lowercase the text\n","    text = lowercase_text(text)\n","\n","    # Step 3: Tokenization\n","    tokens = tokenize_text(text)\n","\n","    # Step 4: Remove punctuation\n","    tokens = remove_punctuation(tokens)\n","\n","    # Step 5: Remove numbers\n","    tokens = remove_numbers(tokens)\n","\n","    # Step 6: Remove special characters\n","    tokens = remove_special_characters(tokens)\n","\n","    # Step 7: Remove stopwords\n","    tokens = remove_stopwords(tokens)\n","\n","    # Step 8: Lemmatization\n","    tokens = lemmatize_text(tokens)\n","\n","    # Step 9: Normalization\n","    tokens = normalize_text(tokens)\n","\n","    # Step 10: Standardization\n","    tokens = standardize_text(tokens)\n","\n","    # Step 11: Stemming\n","    if use_stemming:\n","        tokens = stem_text(tokens)\n","\n","    # Join tokens back to string\n","    processed_text = ' '.join(tokens)\n","\n","    return processed_text\n","\n","\n","\n","# Apply preprocessing function to the dataframe with and without stemming\n","df['Processed_Text_Lemmatization'] = df['Text'].apply(lambda x: preprocess_text(x, use_stemming=False))\n","df['Processed_Text_Stemming'] = df['Text'].apply(lambda x: preprocess_text(x, use_stemming=True))\n","\n","df"]},{"cell_type":"code","source":["import spacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","spacy_stopwords = nlp.Defaults.stop_words\n","print(\"spaCy Stopwords count:\", len(spacy_stopwords))\n","print(\"Sample spaCy Stopwords:\", list(spacy_stopwords)[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycb65I2dgRjC","executionInfo":{"status":"ok","timestamp":1746953208440,"user_tz":-300,"elapsed":8812,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"adf57973-af6b-431c-fa5d-d980c2a3dcbc"},"id":"ycb65I2dgRjC","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["spaCy Stopwords count: 326\n","Sample spaCy Stopwords: ['then', 'seems', 'did', 'whereafter', 'every', 'ten', 'an', 'after', 'namely', 'by', 'give', 'although', 'whose', 'sixty', 'his', 'whole', 'who', 'again', 'moreover', 'hereupon']\n"]}]},{"cell_type":"code","source":["from textblob import Word\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","textblob_stopwords = stopwords.words(\"english\")\n","print(\"TextBlob Stopwords count:\", len(textblob_stopwords))\n","print(\"Sample TextBlob Stopwords:\", textblob_stopwords[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dcylxZy5hYL9","executionInfo":{"status":"ok","timestamp":1746954310656,"user_tz":-300,"elapsed":206,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"b11d431d-a970-4fc3-886c-1af7e84d3d65"},"id":"dcylxZy5hYL9","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TextBlob Stopwords count: 198\n","Sample TextBlob Stopwords: ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["from gensim.parsing.preprocessing import STOPWORDS\n","\n","# Gensim stopwords\n","gensim_stopwords = list(STOPWORDS)\n","\n","# Print the count and a sample of Gensim stopwords\n","print(\"Gensim Stopwords count:\", len(gensim_stopwords))\n","print(\"Sample Gensim Stopwords:\", gensim_stopwords[:20])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHv4-NUNwQ1t","executionInfo":{"status":"ok","timestamp":1746957275609,"user_tz":-300,"elapsed":23,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"ed04cc14-62a0-4667-d641-647f76e65c5c"},"id":"YHv4-NUNwQ1t","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Gensim Stopwords count: 337\n","Sample Gensim Stopwords: ['then', 'seems', 'did', 'whereafter', 'every', 'ten', 'an', 'after', 'namely', 'by', 'cry', 'hasnt', 'give', 'although', 'whose', 'sixty', 'his', 'whole', 'who', 'again']\n"]}]},{"cell_type":"markdown","source":["Stopwords Removal: Library Comparison\n","**NLTK**\n","Source: Manually curated stopwords.\n","\n","Count: ~179 stopwords.\n","\n","Common examples: ['the', 'is', 'in', 'not', 'on']\n","\n","Pros: Widely used, easy to use.\n","\n","Cons: Doesn't update frequently; static list.\n","\n","**spaCy**\n","Source: Built-in linguistic data.\n","\n","Count: ~326 stopwords (en_core_web_sm)\n","\n","Common examples: Includes n’t, 're, 've, etc.\n","\n","Pros: Richer list, includes contractions and symbols.\n","\n","Cons: May include more than needed for some use cases.\n","\n","**Gensim**\n","Source: Inspired by Google's stopwords and extended.\n","\n","Count: ~337 stopwords.\n","\n","Common examples: Similar to spaCy but may include more domain-specific terms.\n","\n","Pros: Lightweight, used for topic modeling.\n","\n","Cons: Slightly less standardized."],"metadata":{"id":"Kn4YUxo9v-Hw"},"id":"Kn4YUxo9v-Hw"},{"cell_type":"code","source":["import spacy\n","import pandas as pd\n","\n","# Load spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Sample DataFrame\n","data = {\n","    'ID': [1, 2, 3, 4, 5, 6],\n","    'Text': [\n","        \"The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.\",\n","        \"Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\",\n","        \"Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\",\n","        \"Muslims fast during the month of Ramadan to cleanse their body and soul.\",\n","        \"Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\",\n","        \"The better player played well and he is a runner.\"\n","    ]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Define the spaCy tokenizer function\n","def spacy_tokenizer(text):\n","    doc = nlp(text)\n","    return [token.text for token in doc]\n","\n","# Apply the tokenizer function to the DataFrame\n","df['spaCy_Tokens'] = df['Text'].apply(spacy_tokenizer)\n","\n","# Ensure the DataFrame is displayed with clear formatting\n","print(df[['ID', 'spaCy_Tokens']].to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONAbjRZrjP5-","executionInfo":{"status":"ok","timestamp":1746955052160,"user_tz":-300,"elapsed":980,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"05181941-b31e-4cbd-d867-0e2a70d1e364"},"id":"ONAbjRZrjP5-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" ID                                                                                                         spaCy_Tokens\n","  1 [The, Qur'an, is, the, holy, book, of, Islam, ., It, 's, written, in, Arabic, ,, and, Muslims, recite, it, daily, .]\n","  2     [Prophet, Muhammad, (, PBUH, ), was, born, in, Mecca, ., He, is, regarded, as, the, last, prophet, of, Islam, .]\n","  3               [Zakat, is, a, mandatory, act, of, charity, in, Islam, ,, aimed, at, helping, the, less, fortunate, .]\n","  4                             [Muslims, fast, during, the, month, of, Ramadan, to, cleanse, their, body, and, soul, .]\n","  5          [Hajj, is, an, annual, pilgrimage, to, Mecca, that, every, Muslim, must, perform, once, in, their, life, .]\n","  6                                                       [The, better, player, played, well, and, he, is, a, runner, .]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from textblob import TextBlob\n","\n","# Sample DataFrame\n","data = {\n","    'ID': [1, 2, 3, 4, 5, 6],\n","    'Text': [\n","        \"The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.\",\n","        \"Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\",\n","        \"Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\",\n","        \"Muslims fast during the month of Ramadan to cleanse their body and soul.\",\n","        \"Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\",\n","        \"The better player played well and he is a runner.\"\n","    ]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Define the TextBlob tokenizer function\n","def textblob_tokenizer(text):\n","    blob = TextBlob(text)\n","    return [word for word in blob.words]\n","\n","# Apply the tokenizer function to the DataFrame\n","df['TextBlob_Tokens'] = df['Text'].apply(textblob_tokenizer)\n","\n","# Ensure the DataFrame is displayed with clear formatting\n","print(df[['ID', 'TextBlob_Tokens']].to_string(index=False))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEanKuJch7oB","executionInfo":{"status":"ok","timestamp":1746954999202,"user_tz":-300,"elapsed":50,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"5440ef61-8c78-476d-e1c6-d22ece070819"},"id":"AEanKuJch7oB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" ID                                                                                             TextBlob_Tokens\n","  1 [The, Qur'an, is, the, holy, book, of, Islam, It, 's, written, in, Arabic, and, Muslims, recite, it, daily]\n","  2        [Prophet, Muhammad, PBUH, was, born, in, Mecca, He, is, regarded, as, the, last, prophet, of, Islam]\n","  3            [Zakat, is, a, mandatory, act, of, charity, in, Islam, aimed, at, helping, the, less, fortunate]\n","  4                       [Muslims, fast, during, the, month, of, Ramadan, to, cleanse, their, body, and, soul]\n","  5    [Hajj, is, an, annual, pilgrimage, to, Mecca, that, every, Muslim, must, perform, once, in, their, life]\n","  6                                                 [The, better, player, played, well, and, he, is, a, runner]\n"]}]},{"cell_type":"markdown","source":["Key Differences:\n","Punctuation Handling:\n","\n","TextBlob: Treats punctuation as part of the word (e.g., \"It's\" stays as one token).\n","\n","spaCy: Separates punctuation from words (e.g., \"It's\" becomes [\"It\", \"'s\"]).\n","\n","Contractions:\n","\n","TextBlob: Splits contractions simply (e.g., \"isn't\" → ['is', 'n', 't']).\n","\n","spaCy: Handles contractions more accurately (e.g., \"isn't\" → ['is', \"n't\"]).\n","\n","Token Granularity:\n","\n","TextBlob: Basic tokenization without splitting punctuation.\n","\n","spaCy: More precise, breaking text into both words and punctuation.\n","\n","Complexity:\n","\n","TextBlob: Fast and straightforward, perfect for simple tasks.\n","\n","spaCy: More advanced, ideal for detailed and production-level NLP tasks.\n","\n"],"metadata":{"id":"mLAmEBM6pciu"},"id":"mLAmEBM6pciu"},{"cell_type":"code","source":["import pandas as pd\n","from textblob import TextBlob\n","import spacy\n","\n","# Sample DataFrame\n","data = {\n","    'ID': [1, 2, 3, 4, 5, 6],\n","    'Text': [\n","        \"The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.\",\n","        \"Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\",\n","        \"Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\",\n","        \"Muslims fast during the month of Ramadan to cleanse their body and soul.\",\n","        \"Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\",\n","        \"The better player played well and he is a runner.\"\n","    ]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Define the TextBlob tokenizer function\n","def textblob_tokenizer(text):\n","    blob = TextBlob(text)\n","    return [word for word in blob.words]\n","\n","# Define the spaCy tokenizer function\n","nlp = spacy.load(\"en_core_web_sm\")\n","def spacy_tokenizer(text):\n","    doc = nlp(text)\n","    return [token.text for token in doc]\n","\n","# Apply the tokenizers to the DataFrame\n","df['TextBlob_Tokens'] = df['Text'].apply(textblob_tokenizer)\n","df['spaCy_Tokens'] = df['Text'].apply(spacy_tokenizer)\n","\n","# Display the DataFrame with separate columns for each tokenizer\n","print(\"TextBlob Tokenized Output:\")\n","print(df[['ID', 'TextBlob_Tokens']].to_string(index=False))\n","\n","print(\"\\nspaCy Tokenized Output:\")\n","print(df[['ID', 'spaCy_Tokens']].to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MI33CLrQqLWN","executionInfo":{"status":"ok","timestamp":1746955525358,"user_tz":-300,"elapsed":1439,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"21ea642b-2f2c-463d-aa23-7979fdad9b6b"},"id":"MI33CLrQqLWN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TextBlob Tokenized Output:\n"," ID                                                                                             TextBlob_Tokens\n","  1 [The, Qur'an, is, the, holy, book, of, Islam, It, 's, written, in, Arabic, and, Muslims, recite, it, daily]\n","  2        [Prophet, Muhammad, PBUH, was, born, in, Mecca, He, is, regarded, as, the, last, prophet, of, Islam]\n","  3            [Zakat, is, a, mandatory, act, of, charity, in, Islam, aimed, at, helping, the, less, fortunate]\n","  4                       [Muslims, fast, during, the, month, of, Ramadan, to, cleanse, their, body, and, soul]\n","  5    [Hajj, is, an, annual, pilgrimage, to, Mecca, that, every, Muslim, must, perform, once, in, their, life]\n","  6                                                 [The, better, player, played, well, and, he, is, a, runner]\n","\n","spaCy Tokenized Output:\n"," ID                                                                                                         spaCy_Tokens\n","  1 [The, Qur'an, is, the, holy, book, of, Islam, ., It, 's, written, in, Arabic, ,, and, Muslims, recite, it, daily, .]\n","  2     [Prophet, Muhammad, (, PBUH, ), was, born, in, Mecca, ., He, is, regarded, as, the, last, prophet, of, Islam, .]\n","  3               [Zakat, is, a, mandatory, act, of, charity, in, Islam, ,, aimed, at, helping, the, less, fortunate, .]\n","  4                             [Muslims, fast, during, the, month, of, Ramadan, to, cleanse, their, body, and, soul, .]\n","  5          [Hajj, is, an, annual, pilgrimage, to, Mecca, that, every, Muslim, must, perform, once, in, their, life, .]\n","  6                                                       [The, better, player, played, well, and, he, is, a, runner, .]\n"]}]},{"cell_type":"markdown","source":["Quick Comparison: TextBlob vs. spaCy vs. NLTK Lemmatizer\n","TextBlob:\n","Fast and easy for basic tasks. Great for simple tokenization and lemmatization but lacks precision for complex text. Perfect when you need quick results without much effort.\n","\n","spaCy:\n","Powerful and accurate, designed for complex projects. Splits punctuation correctly and lemmatizes with context. Best for larger datasets and tasks requiring high precision, but needs more setup than TextBlob.\n","\n","NLTK Lemmatizer:\n","Deep and precise, using WordNet to accurately lemmatize words. Best for detailed linguistic tasks but requires extra steps like part-of-speech tagging. Slower than spaCy but highly accurate for nuanced language tasks."],"metadata":{"id":"OuZrbE2jrGCq"},"id":"OuZrbE2jrGCq"},{"cell_type":"code","source":["import pandas as pd\n","from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n","\n","# Sample DataFrame\n","data = {\n","    'ID': [1, 2, 3, 4, 5, 6],\n","    'Text': [\n","        \"The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.\",\n","        \"Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\",\n","        \"Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\",\n","        \"Muslims fast during the month of Ramadan to cleanse their body and soul.\",\n","        \"Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\",\n","        \"The better player played well and he is a runner.\"\n","    ]\n","}\n","\n","# Create DataFrame\n","df = pd.DataFrame(data)\n","\n","# Initialize stemmers\n","porter = PorterStemmer()\n","snowball = SnowballStemmer(\"english\")\n","lancaster = LancasterStemmer()\n","\n","# Define a function to stem words with each stemmer\n","def apply_stemmers(text):\n","    words = text.split()  # Split the text into words\n","    porter_stemmed = [porter.stem(word) for word in words]\n","    snowball_stemmed = [snowball.stem(word) for word in words]\n","    lancaster_stemmed = [lancaster.stem(word) for word in words]\n","\n","    return porter_stemmed, snowball_stemmed, lancaster_stemmed\n","\n","# Apply the stemming function to each row in the 'Text' column\n","df[['Porter_Stemmed', 'Snowball_Stemmed', 'Lancaster_Stemmed']] = df['Text'].apply(lambda x: pd.Series(apply_stemmers(x)))\n","\n","# Display the DataFrame with the stemmed results\n","print(df[['ID', 'Text', 'Porter_Stemmed', 'Snowball_Stemmed', 'Lancaster_Stemmed']].to_string(index=False))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zfnt7pQEr1A-","executionInfo":{"status":"ok","timestamp":1746956081069,"user_tz":-300,"elapsed":42,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"c05640da-a715-4f78-a1a5-18dbd0c0f8fa"},"id":"Zfnt7pQEr1A-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" ID                                                                                       Text                                                                                            Porter_Stemmed                                                                                         Snowball_Stemmed                                                                                       Lancaster_Stemmed\n","  1 The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily. [the, qur'an, is, the, holi, book, of, islam., it', written, in, arabic,, and, muslim, recit, it, daily.] [the, qur'an, is, the, holi, book, of, islam., it, written, in, arabic,, and, muslim, recit, it, daily.] [the, qur'an, is, the, holy, book, of, islam., it's, writ, in, arabic,, and, muslim, recit, it, daily.]\n","  2    Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.     [prophet, muhammad, (pbuh), wa, born, in, mecca., he, is, regard, as, the, last, prophet, of, islam.]   [prophet, muhammad, (pbuh), was, born, in, mecca., he, is, regard, as, the, last, prophet, of, islam.]  [prophet, muhammad, (pbuh), was, born, in, mecca., he, is, regard, as, the, last, prophet, of, islam.]\n","  3         Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.             [zakat, is, a, mandatori, act, of, chariti, in, islam,, aim, at, help, the, less, fortunate.]            [zakat, is, a, mandatori, act, of, chariti, in, islam,, aim, at, help, the, less, fortunate.]                     [zak, is, a, mand, act, of, char, in, islam,, aim, at, help, the, less, fortunate.]\n","  4                   Muslims fast during the month of Ramadan to cleanse their body and soul.                        [muslim, fast, dure, the, month, of, ramadan, to, cleans, their, bodi, and, soul.]                       [muslim, fast, dure, the, month, of, ramadan, to, cleans, their, bodi, and, soul.]                           [muslim, fast, dur, the, mon, of, ramad, to, cleans, their, body, and, soul.]\n","  5   Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.   [hajj, is, an, annual, pilgrimag, to, mecca, that, everi, muslim, must, perform, onc, in, their, life.]  [hajj, is, an, annual, pilgrimag, to, mecca, that, everi, muslim, must, perform, onc, in, their, life.]        [hajs, is, an, an, pilgrim, to, mecc, that, every, muslim, must, perform, ont, in, their, life.]\n","  6                                          The better player played well and he is a runner.                                                [the, better, player, play, well, and, he, is, a, runner.]                                               [the, better, player, play, well, and, he, is, a, runner.]                                                    [the, bet, play, play, wel, and, he, is, a, runner.]\n"]}]},{"cell_type":"markdown","source":["**Porter Stemmer**\n","One of the oldest and most widely used stemmers.\n","\n","Applies a set of rules to strip suffixes while keeping the word recognizable (e.g., \"connection\" → \"connect\").\n","\n","Best for: General NLP tasks where you need balance between accuracy and simplicity.\n","**Lancaster Stemmer**\n","Much more aggressive than Porter—it chops words down heavily.\n","\n","May produce stems that aren't real words (e.g., \"universal\" → \"univers\").\n","\n","Best for: Fast, exploratory tasks where exact meaning isn’t critical.\n","**Snowball Stemmer**\n","A modernized version of Porter with more consistent rules.\n","\n","Less aggressive and more accurate than Lancaster.\n","\n","Supports multiple languages.\n","\n","Best for: Robust NLP tasks requiring better precision and language flexibility."],"metadata":{"id":"8PwyBJCVunE6"},"id":"8PwyBJCVunE6"},{"cell_type":"code","source":["import re\n","import spacy\n","from textblob import Word\n","import contractions\n","\n","# Load the spaCy model\n","nlp = spacy.load('en_core_web_sm')\n"],"metadata":{"id":"Fxyiib6hyUH4"},"id":"Fxyiib6hyUH4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for Lowercasing using TextBlob\n","def lowercase_text(text):\n","    return text.lower()\n","\n","# Function for Lowercasing using spaCy\n","def spacy_lowercase(text):\n","    doc = nlp(text)\n","    return \" \".join([token.text.lower() for token in doc])\n"],"metadata":{"id":"MY_sD9-wyZzw"},"id":"MY_sD9-wyZzw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for Removing Special Characters using TextBlob\n","def remove_special_characters(text):\n","    return re.sub(r'[^a-zA-Z\\s]', '', text)\n","\n","# Function for Removing Special Characters using spaCy\n","def spacy_remove_special_characters(text):\n","    doc = nlp(text)\n","    return \" \".join([token.text for token in doc if token.is_alpha])\n"],"metadata":{"id":"PcrWSCeeyrJW"},"id":"PcrWSCeeyrJW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for Removing Numbers using TextBlob\n","def remove_numbers(text):\n","    return re.sub(r'\\d+', '', text)\n","\n","# Function for Removing Numbers using spaCy\n","def spacy_remove_numbers(text):\n","    doc = nlp(text)\n","    return \" \".join([token.text for token in doc if not token.is_digit])\n"],"metadata":{"id":"U__wwjHPytS9"},"id":"U__wwjHPytS9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for Handling Contractions using TextBlob\n","def expand_contractions(text):\n","    return contractions.fix(text)\n","\n","# Function for Handling Contractions using spaCy\n","def spacy_expand_contractions(text):\n","    # spaCy itself doesn't provide contraction handling out-of-the-box.\n","    # So we use the contractions library here.\n","    return contractions.fix(text)\n"],"metadata":{"id":"q6IwV0OCyvYp"},"id":"q6IwV0OCyvYp","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import contractions\n","\n","# Sample DataFrame\n","data = {\n","    'ID': [1, 2, 3, 4, 5, 6],\n","    'Text': [\n","        \"The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.\",\n","        \"Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\",\n","        \"Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\",\n","        \"Muslims fast during the month of Ramadan to cleanse their body and soul.\",\n","        \"Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\",\n","        \"The better player played well and he is a runner.\"\n","    ]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Sample functions for text cleaning\n","def lowercase_text(text):\n","    return text.lower()\n","\n","def remove_special_characters(text):\n","    return re.sub(r'[^a-zA-Z\\s]', '', text)\n","\n","def remove_numbers(text):\n","    return re.sub(r'\\d+', '', text)\n","\n","def expand_contractions(text):\n","    return contractions.fix(text)\n","\n","# Apply Text Cleaning Functions\n","df['Lowercased_Text'] = df['Text'].apply(lowercase_text)\n","df['Special_Char_Removed'] = df['Text'].apply(remove_special_characters)\n","df['Numbers_Removed'] = df['Text'].apply(remove_numbers)\n","df['Contractions_Expanded'] = df['Text'].apply(expand_contractions)\n","\n","# Printing each result separately with better formatting\n","\n","# Print Lowercased Text\n","print(\"\\n----- Lowercased Text -----\")\n","print(df[['ID', 'Lowercased_Text']].to_string(index=False))\n","\n","# Print Special Characters Removed\n","print(\"\\n----- Special Characters Removed -----\")\n","print(df[['ID', 'Special_Char_Removed']].to_string(index=False))\n","\n","# Print Numbers Removed\n","print(\"\\n----- Numbers Removed -----\")\n","print(df[['ID', 'Numbers_Removed']].to_string(index=False))\n","\n","# Print Contractions Expanded\n","print(\"\\n----- Contractions Expanded -----\")\n","print(df[['ID', 'Contractions_Expanded']].to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcoIKEUozyCF","executionInfo":{"status":"ok","timestamp":1746958196539,"user_tz":-300,"elapsed":62,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"1a691e06-2a3b-48d0-ddb1-9d345141f408"},"id":"qcoIKEUozyCF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","----- Lowercased Text -----\n"," ID                                                                            Lowercased_Text\n","  1 the qur'an is the holy book of islam. it's written in arabic, and muslims recite it daily.\n","  2    prophet muhammad (pbuh) was born in mecca. he is regarded as the last prophet of islam.\n","  3         zakat is a mandatory act of charity in islam, aimed at helping the less fortunate.\n","  4                   muslims fast during the month of ramadan to cleanse their body and soul.\n","  5   hajj is an annual pilgrimage to mecca that every muslim must perform once in their life.\n","  6                                          the better player played well and he is a runner.\n","\n","----- Special Characters Removed -----\n"," ID                                                                    Special_Char_Removed\n","  1   The Quran is the holy book of Islam Its written in Arabic and Muslims recite it daily\n","  2     Prophet Muhammad PBUH was born in Mecca He is regarded as the last prophet of Islam\n","  3        Zakat is a mandatory act of charity in Islam aimed at helping the less fortunate\n","  4                 Muslims fast during the month of Ramadan to cleanse their body and soul\n","  5 Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life\n","  6                                        The better player played well and he is a runner\n","\n","----- Numbers Removed -----\n"," ID                                                                            Numbers_Removed\n","  1 The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.\n","  2    Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\n","  3         Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\n","  4                   Muslims fast during the month of Ramadan to cleanse their body and soul.\n","  5   Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\n","  6                                          The better player played well and he is a runner.\n","\n","----- Contractions Expanded -----\n"," ID                                                                       Contractions_Expanded\n","  1 The Qur'an is the holy book of Islam. It is written in Arabic, and Muslims recite it daily.\n","  2     Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\n","  3          Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\n","  4                    Muslims fast during the month of Ramadan to cleanse their body and soul.\n","  5    Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\n","  6                                           The better player played well and he is a runner.\n"]}]},{"cell_type":"markdown","source":["Explanation of Text Cleaning Techniques\n","Lowercasing:\n","\n","Purpose: Converts all text to lowercase to remove case sensitivity.\n","\n","Why: Treats words like \"Islam\" and \"islam\" as the same.\n","\n","Example: \"The Qur'an\" → \"the qur'an\"\n","\n","Removing Special Characters:\n","\n","Purpose: Eliminates punctuation, parentheses, and symbols.\n","\n","Why: These do not contribute meaning and can disrupt NLP tasks.\n","\n","Example: \"Prophet Muhammad (PBUH)\" → \"Prophet Muhammad PBUH\"\n","\n","Removing Numbers:\n","\n","Purpose: Removes digits that aren't relevant in most text analysis tasks.\n","\n","Why: Focuses on the content of the words.\n","\n","Example: \"30 days\" → \" days\"\n","\n","Handling Contractions:\n","\n","Purpose: Expands shortened words (e.g., \"it's\" to \"it is\").\n","\n","Why: Standardizes text and reduces ambiguity.\n","\n","Example: \"It's raining\" → \"It is raining\"\n","\n","Benefits:\n","Consistency: Ensures uniformity across the text.\n","\n","Noise Reduction: Removes irrelevant characters and numbers.\n","\n","Improved Model Accuracy: Helps NLP models focus on meaningful words."],"metadata":{"id":"c_222PdB1NBz"},"id":"c_222PdB1NBz"},{"cell_type":"code","source":["import pandas as pd\n","import spacy\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from nltk.stem import PorterStemmer, SnowballStemmer\n","from spacy.lang.en import English\n","from sklearn.base import BaseEstimator, TransformerMixin\n","\n","# Load spaCy model for lemmatization\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Sample DataFrame\n","data = {\n","    'ID': [1, 2, 3, 4, 5, 6],\n","    'Text': [\n","        \"The Qur'an is the holy book of Islam. It's written in Arabic, and Muslims recite it daily.\",\n","        \"Prophet Muhammad (PBUH) was born in Mecca. He is regarded as the last prophet of Islam.\",\n","        \"Zakat is a mandatory act of charity in Islam, aimed at helping the less fortunate.\",\n","        \"Muslims fast during the month of Ramadan to cleanse their body and soul.\",\n","        \"Hajj is an annual pilgrimage to Mecca that every Muslim must perform once in their life.\",\n","        \"The better player played well and he is a runner.\"\n","    ]\n","}\n","\n","df = pd.DataFrame(data)\n"],"metadata":{"id":"ss89Lktq0p1N"},"id":"ss89Lktq0p1N","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a function to apply Lemmatization using spaCy\n","def lemmatize_text(text):\n","    doc = nlp(text)\n","    return \" \".join([token.lemma_ for token in doc])\n","\n","# Define Stemming function (using NLTK's PorterStemmer for demonstration)\n","def stem_text(text, stemmer_type=\"porter\"):\n","    words = text.split()\n","    if stemmer_type == \"porter\":\n","        stemmer = PorterStemmer()\n","    elif stemmer_type == \"snowball\":\n","        stemmer = SnowballStemmer(\"english\")\n","\n","    return \" \".join([stemmer.stem(word) for word in words])\n","\n","# Combine different preprocessing techniques\n","def preprocess_text(text, use_stemming=False, stemmer_type=\"porter\"):\n","    # Lowercase text, remove special characters, etc.\n","    text = text.lower()\n","    text = ''.join([char for char in text if char.isalnum() or char.isspace()])  # Remove special characters\n","\n","    if use_stemming:\n","        return stem_text(text, stemmer_type)\n","    else:\n","        return lemmatize_text(text)\n"],"metadata":{"id":"5r1i5tbI1lp0"},"id":"5r1i5tbI1lp0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))  # Extract unigrams and bigrams\n","X_tfidf = tfidf_vectorizer.fit_transform(df['Text'])\n","\n","# Display extracted features (n-grams)\n","feature_names = tfidf_vectorizer.get_feature_names_out()\n","print(\"Extracted Features (Unigrams and Bigrams):\")\n","print(feature_names[:20])  # Show first 20 features\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PmVlmX61nrm","executionInfo":{"status":"ok","timestamp":1746958459800,"user_tz":-300,"elapsed":50,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"c899781e-163f-4092-f009-d693f66a8853"},"id":"8PmVlmX61nrm","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Features (Unigrams and Bigrams):\n","['act' 'act of' 'aimed' 'aimed at' 'an' 'an annual' 'an is' 'and' 'and he'\n"," 'and muslims' 'and soul' 'annual' 'annual pilgrimage' 'arabic'\n"," 'arabic and' 'as' 'as the' 'at' 'at helping' 'better']\n"]}]},{"cell_type":"code","source":["# Custom transformer to apply lemmatization or stemming in a pipeline\n","class TextPreprocessor(BaseEstimator, TransformerMixin):\n","    def __init__(self, use_stemming=False, stemmer_type=\"porter\"):\n","        self.use_stemming = use_stemming\n","        self.stemmer_type = stemmer_type\n","\n","    def fit(self, X, y=None):\n","        return self  # No fitting necessary\n","\n","    def transform(self, X):\n","        return [preprocess_text(text, use_stemming=self.use_stemming, stemmer_type=self.stemmer_type) for text in X]\n","\n","# Create a pipeline combining text preprocessing and feature extraction\n","pipeline = Pipeline([\n","    ('preprocessor', TextPreprocessor(use_stemming=True, stemmer_type=\"porter\")),  # Can toggle stemming or lemmatization\n","    ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1, 2)))  # Extract unigrams and bigrams\n","])\n","X_pipeline = pipeline.fit_transform(df['Text'])\n","print(\"Extracted n-grams with preprocessing pipeline:\")\n","feature_names_pipeline = pipeline.named_steps['vectorizer'].get_feature_names_out()\n","print(feature_names_pipeline[:20])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TEdK1R7s1qG-","executionInfo":{"status":"ok","timestamp":1746958468078,"user_tz":-300,"elapsed":20,"user":{"displayName":"AMNA MIRAJ","userId":"13907306903305565739"}},"outputId":"c7a5bba2-e4f2-42ca-eb9b-d427433dadbd"},"id":"TEdK1R7s1qG-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted n-grams with preprocessing pipeline:\n","['act' 'act of' 'aim' 'aim at' 'an' 'an annual' 'and' 'and he'\n"," 'and muslim' 'and soul' 'annual' 'annual pilgrimag' 'arab' 'arab and'\n"," 'as' 'as the' 'at' 'at help' 'better' 'better player']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"UWZBXCYg1sIy"},"id":"UWZBXCYg1sIy","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[{"file_id":"1C5pFJQtBBh_K8UUlmPhZUpPf_PizrlIM","timestamp":1746964829645},{"file_id":"1ypOSFuzoGbACuP3nV2cRhDkl5GODmaN7","timestamp":1746960052647}]}},"nbformat":4,"nbformat_minor":5}